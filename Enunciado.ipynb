{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 2 - Fronteras no Lineales </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* similaridad: KNN\n",
    "* Selección de hı́per-parámetros estructurales en SVM, Arboles de Decisión, k-NN y Redes Neuronales.\n",
    "* Métodos de *kernel*.\n",
    "* Extracción de características.\n",
    "* Múltiples anotaciones\n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de discusión y entrega: 8 de Noviembre.\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea2-INF393-II-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "### Paquetes de instalación\n",
    "\n",
    "Como es usual utilizaremos *numpy, scipy, matplotlib* y *sklearn*. Además de éstas se necesitará instalar **keras**, una librerı́a en python para prototipado rápido de modelos basados en redes neuronales, muy similar en espı́ritu a *sklearn*. La librerı́a puede usar *TensorFlow* o *Theano* como backend, siendo éstas las librerı́as más populares para desarrollar nuevos modelos de redes neuronales o implementar eficientemente modelos conocidos con fines prácticos. Para detalles sobre la instalación puede revisar [[1]](#refs) o escribir un email a su ayudante.\n",
    "\n",
    "\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Sentiment Analysis en Texto  \n",
    "[2.](#segundo) pendiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Sentiment Analysis en Texto\n",
    "\n",
    "El análisis de emociones o sentimientos se refiere al proceso de extraer información acerca de la actitud\n",
    "que una persona (o grupo de ellas) manifiesta, en un determinado medio o formato digital, con respecto a un\n",
    "tópico o contexto de comunicación. Uno de los casos más estudiados corresponde a determinar la polaridad\n",
    "de un trozo de texto, es decir, clasificar una determinada evaluación escrita (*review*), en que una persona\n",
    "manifiesta una opinión, como *positiva*, *negativa* o *neutral*. Esto también ha sido extendido a otros medios, como lo es analizar la polaridad de textos en redes sociales.  La dificultad de este problema radica en el carácter altamente ambiguo e informal del lenguaje que utilizan naturalmente las personas ası́ como el manejo de negaciones, sarcasmo y abreviaciones en una frase.\n",
    "\n",
    "<img src=\"https://formtitanhelpdeskimage.s3.amazonaws.com/70c78f9df2fd5c130e7021644f78f4c5.jpg\" title=\"Title text\" width=\"40%\" />\n",
    "\n",
    "\n",
    "Los datos que usaremos para esta actividad corresponden a un subconjunto de los datos publicados en **Kaggle**,  en  el  contexto  de  una  competencia  organizada  por  la  Universidad  de  Stanford  [[2]](#refs).   Cada  registro disponible corresponderá a una opinión sobre una película, registrada sobre el sitio *Rotten Tomatoes*.  Para empezar  nos  limitaremos  a  estudiar  textos  anotados  como  positivos  o  negativos,  clases  que  codificaremos como +1 y 0 respectivamente. Los datos pueden ser descargados ejecutando el siguiente código en sistema Unix:\n",
    "```\n",
    "wget -O train_data.csv http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\n",
    "wget -O test_data.csv http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\n",
    "```\n",
    "\n",
    "> Cargue los dos conjuntos de datos a ser trabajados, donde la etiqueta ya viene codificada y la dejaremos como negativo (0) y positivo (1).\n",
    "```python\n",
    "import pandas as pd\n",
    "ftr = open(\"train_data.csv\", \"r\",  encoding=\"ISO-8859-1\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "df_train = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "df_train['Sentiment'] = (pd.to_numeric(df_train['Sentiment'])+1)/2 # 0 o 1\n",
    "fts = open(\"test_data.csv\", \"r\",  encoding=\"ISO-8859-1\")\n",
    "... #same loading for test\n",
    "df_train_text = df_train.Text\n",
    "df_test_text = df_test.Text\n",
    "labels_train = df_train.Sentiment.values\n",
    "labels_test = df_test.Sentiment.values\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"pip3\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = open(\"./Data/train_data.csv\", \"r\",  encoding=\"ISO-8859-1\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "\n",
    "# Train Dataset\n",
    "df_train = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "df_train['Sentiment'] = (pd.to_numeric(df_train['Sentiment'])+1)/2 # 0 o 1\n",
    "\n",
    "ftr = open(\"./Data/test_data.csv\", \"r\",  encoding=\"ISO-8859-1\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "\n",
    "# Test Dataset\n",
    "df_test = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "df_test['Sentiment'] = (pd.to_numeric(df_test['Sentiment'])+1)/2 # 0 o 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> a) Describa los datos trabajados, como la cantidad de datos en cada conjunto, largo de los textos, la cantidad de ejemplo por cada clase, o alguna otra forma que piense que pueda ser útil para comprender el problema trabajado.\n",
    "```python\n",
    "df_train_sentiment.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de  entrenamiento\n",
      "------------------------\n",
      "Total de datos 3554\n",
      "Cantidad de datos positivos:  1770\n",
      "Cantidad de datos etiquetados negativamente:  1784\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH2tJREFUeJzt3XmYHVWd//H3h7BIWISQgCELAQyMAVGZFhlFzU9QAYEgCoIIAdGIg+ICPxZxhrjwCDOu44ITBAFFIKJC3FmGyCCyhEVWkciShAQShLAIAsHv/HFOk8rldPftTt9bvXxez9NPV53avqfq3vu951TdKkUEZmZmjdaoOwAzMxuYnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAmiH0n6rqR/66d1TZT0lKQReXyupA/1x7obtvOUpK36e72F7Zwt6YtNznu/pN1Wdz3t1qpjNFRIOljSpXXH0RNJb5Z0dzfTV3lvDmVOEE3KH1rPSHpS0nJJ10g6UtKL+zAijoyILzS5ruIHYGVdCyJi/Yh4oT/i72Y760fEva3chg1+/ZGYI+K8iHhHf8XUKhHxvxGxbed44/u1Xe/NgcAJonf2jogNgC2AU4HjgTP7eyOS1uzvdQ53Svx6r4lf04OT3zB9EBGPR8Qc4H3AdEnbw6rfsiSNlvSL3Np4VNL/SlpD0g+AicDPczP1OEmTJIWkIyQtAP6nUlZ9Y20t6XpJj0u6RNKovK2pkhZVY6x+65E0QtJnJP0lt4BulDQhTwtJr8zDL5d0rqRlkh6Q9NnOD1VJh0m6WtKXJT0m6T5Je3S1jyS9TtJNeXsXAi9rmL6XpFsqrbEdenscJG2c9/GyHNMvJI2vTJ8r6RRJvweeBraStKWkq3Jcl0v6tqQfVpbZR9IdOa65kl7VzfbfLulP+Xh8C1DD9A9KuivH9ltJW3Szrl3yflguaaGkw3J5T8fk95K+lpe7V9Ibc/lCSUslTa9sY518/BZIelipS3TdPG2qpEWSjsnLLZF0eJ42AzgYOC6/Zn+ey0+ovKbulPTuyraqsT0KzOx8DVXmeaOkG/L+u0HSGxuWvzev+z5JB3ex32ZKukjShXnemyS9pjL9Vfk4Ls/HdZ/KtD1z3E9KelDSsdV9kYe7e7+uKelASfMaYvqUpDlNHL9XSvpdrv8jSu+TgSUi/NfEH3A/sFuhfAHw0Tx8NvDFPPwl4LvAWvnvzYBK6wImAQGcC6wHrFspWzPPMxd4ENg+z/MT4Id52lRgUVfxAv8fuA3YlvQh9hpgkzwtgFfm4XOBS4AN8vb/DByRpx0GPA98GBgBfBRY3Fmnhm2vDTwAfCrX/b152c59syOwFHhDXtf0HO863e3rwj7eBHgPMDLH/GPg4sq8c/Px2Q5YM8fyB+DLOcZdgCcq+3Eb4G/A2/O8xwHzgbULcYzOy743z/spYAXwoTx937zsq/K2Pwtc00WdJgJPAgfldW0CvLbJY7ICODzvxy/m+n4bWAd4R17v+nn+rwNzgFF5fT8HvlR5Da0APp9j2JOUVDdu3O+VuPcHNid90Xxf3ndjG2L7eK7/urns6jx9FPAYcEieflAe34T0+n4C2DbPOxbYrot9N5P02uo8DscC97HyfTcf+Ew+3m/L+6NzvUuAN+fhjYEdS+8nun6/rkl67T0JTK5MvwE4sInjdz5wUt5/LwN2qftz7iX7t+4ABstf44ukUn4tcFIefvFNlN9ol5A/fLtbV+UFt1XpRZjH5wKnVqZPAZ4jfTCs8oJu3AZwNzCti3oF8Mq8nmeBKZVpHwHm5uHDgPmVaSPzsq8orPMtNCQP4JrKvjkd+ELDMncDb+1uXzfu48K01wKPVcbnAp+vjE8kfWiNrJT9kJUJ4t+A2ZVpa5CS8tTCtg4Frq2MC1jEygTx684Pgsq6nga2KKzrROBnhfJmjsk9lWmvzsdks0rZX/N+EekDfOvKtH8B7svDU4FnOl9vuWwpsHNP+70y/y2dr7Mc24KG6YexMkEcAlzfMP0PeZ71gOWk5L9uD9uc2XAc1iB/8Oe/h4A1KtPPB2bm4QV5f27YsM6pNJkgKq+hf8/Dk0kJY2QTx+9cYBYwvrs61vnnLqbVNw54tFD+n6RvL5fmpvIJTaxrYS+mP0D6hjS6ifVOAP7SwzyjWfnNv7qNcZXxhzoHIuLpPLh+YV2bAw9GfhdU1tVpC+CY3OxfLml5jnHzHmJchaSRkv47N92fAK4CNtKqV5dU99nmwKOV2EvTX4wzIv6Rp1f3QXXehZV5o2FdWwDfqNTvUdKHdGldXR2fZo7Jw5XhZ3IsjWXrA2NIH1o3VmL6TS7v9NeIWFEZf5ry8QVA0qFa2U24nNS6rb4eu3s9r7Kvq3WLiL+RWiRHAksk/VLSP3Wzrupx+AcpUW+e/xbmslW2kYffQ2opPZC7ev6lm21050ekFhDA+0mt2Kfp+fgdR3pNXJ+7vz7Yx+23jBPEapD0etLBvrpxWkQ8GRHHRMRWwN7ApyXt2jm5i1X2dGvdCZXhiaSm9SOkb4YjK3GNYNU3/kJg6x7W/UheX7WffCLpG3RvLQHGSar2yU9siOeUiNio8jcyIs7v5XaOIXWbvSEiNiS1XGDVcwHVfboEGCVpZKWsuk8XU6l/jn8C5X2wpLpsZd5OC4GPNNRx3Yi4prCuro5Pfx6TR0jJYrtKPC+PiC4TQINVXptK51POAD5G6q7cCLidrvd9o1X2dfZi3SLitxHxdlL30p/ytrpSPQ5rAOPz+hcDE7TqxQnVbdwQEdOATYGLgdldrL+n9+WlwGhJryUlih/l8m6PX0Q8FBEfjojNSS2L7yifDxwonCD6QNKGkvYCLiB1T9xWmGevfBJKpP7UF/IfpG99ffntwQckTckfcJ8HLop0qd2fgZdJepektUj93etUlvse8AVJk5XsIGmT6orzemYDp0jaIH8AfJrUfO6tP5C6co7OJ/L2A3aqTD8DOFLSG3I86+XYN+jldjYgfegtVzphf3J3M0fEA8A80gnTtfM3xr0rs8wG3iVp17wfjyF1EZQ+1H8JbCdpP6ULCY4GXlGZ/l3gREnbwYsnK/fvIrTzgN0kHZD31yaSXtufxyR/iz4D+JqkTXNM4yS9s8lVNL5m1yN9cC7L6zqc1IJo1q+AbSS9P9f5faRu019I2kzpYoH1SPv/KVa+d0r+uXIcPpmXuRa4jvTl6ThJa0maSjreF+Tjf7Ckl0fE86x8jzZT91XkVtdFpF6DUcBlubzb4ydpf628qOIx0v4cUJfOOkH0zs8lPUn6xncS8FXSCcKSycDlpBf3H4DvRMTcPO1LwGdz0/zYXmz/B6S+4IdIJ7WOhnRVFfCvpETwIOlNUb2q6aukF+qlpDfCmaSTho0+npe9l9Qq+hFwVi/iI8fzHLAfqT/5MVJ3wU8r0+eRTnZ/K0+fn+ftra+T6vEI6QPhN00sczCp7/2vpJO6F5I+UIiIu4EPAN/M69ybdGnzc40riYhHSCdpT83rmgz8vjL9Z8BppA+jJ0jfrotXfUXEAlJXxzGkrqhbSBcSQD8dk+x40r6+Nsd0OakF1owzgSn5NXtxRNwJfIX02n6YdP7j992toCoi/grsRarzX0ndLXvl/bpGLl9M2h9vJb2+u3IJ6TXWedJ7v4h4Ph+3fUj7/RHgO8ChEfGnvNwhwP15XxxJOvYlzbxffwTsBvy4oZuuu+P3euA6SU+RLh74RETc1009267zqhqzYSlfWviniOi29WEDk6SZpAtBuvpwt9XgFoQNK5JeL2lrpd+k7A5MI/U/m1kD/7rRhptXkLq7NiF1w300Im6uNySzgcldTGZmVuQuJjMzKxrUXUyjR4+OSZMm1R2GmdmgcuONNz4SEWN6mm9QJ4hJkyYxb968nmc0M7MXSWr8FXuRu5jMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrKhlv6SWdBbpgSBLI2L7SvnHSY8pXAH8MiKOy+UnAkeQnqh0dET8tlWxWWvNnFnPsmbWv1p5q42zSU8MO7ezQNL/I91/f4eIeLby6MMpwIHAdqQHjV8uaZv8yD4bRvqaIJxYzPpfy7qYIuIq0uMCqz4KnBoRnY94XJrLpwEXRMSz+ZF781n1GcZmZtZm7T4HsQ3wZknXSfqdpNfn8nGk5zx3WpTLzMysJu2+m+uawMbAzqQHds+WtBWgwrzFJxlJmgHMAJg4cWKLwjQzs3a3IBYBP43keuAfwOhcPqEy33hgcWkFETErIjoiomPMmB5vZ25mZn3U7gRxMfA2AEnbAGsDjwBzgAMlrSNpS2AycH2bYzMzs4pWXuZ6PjAVGC1pEXAycBZwlqTbgeeA6ZEein2HpNnAnaTLX4/yFUxmZvVqWYKIiIO6mPSBLuY/BTilVfGYmVnv+JfUZmZWNKifSW3Wyb/eNut/bkGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRX5dt827PX1dt++TbgNdS1rQUg6S9LS/HjRxmnHSgpJo/O4JP2XpPmSbpW0Y6viMjOz5rSyi+lsYPfGQkkTgLcDCyrFewCT898M4PQWxmVmZk1oWYKIiKuARwuTvgYcB0SlbBpwbiTXAhtJGtuq2MzMrGdtPUktaR/gwYj4Y8OkccDCyviiXFZaxwxJ8yTNW7ZsWYsiNTOztiUISSOBk4B/L00ulEWhjIiYFREdEdExZsyY/gzRzMwq2nkV09bAlsAfJQGMB26StBOpxTChMu94YHEbYzMzswZta0FExG0RsWlETIqISaSksGNEPATMAQ7NVzPtDDweEUvaFZuZmb1UKy9zPR/4A7CtpEWSjuhm9l8B9wLzgTOAf21VXGZm1pyWdTFFxEE9TJ9UGQ7gqFbFYmZmvedbbZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRW183kQZkPKzJn1LGvWLk4QQ5w/xMysr9zFZGZmRU4QZmZW1Monyp0laamk2ytl/ynpT5JulfQzSRtVpp0oab6kuyW9s1VxmZlZc1rZgjgb2L2h7DJg+4jYAfgzcCKApCnAgcB2eZnvSBrRwtjMzKwHrXzk6FWSJjWUXVoZvRZ4bx6eBlwQEc8C90maD+xEeqa11cQnqc2GtzrPQXwQ+HUeHgcsrExblMteQtIMSfMkzVu2bFmLQzQzG75qSRCSTgJWAOd1FhVmi9KyETErIjoiomPMmDGtCtHMbNhr++8gJE0H9gJ2jYjOJLAImFCZbTywuN2xmZnZSm1tQUjaHTge2Ccinq5MmgMcKGkdSVsCk4Hr2xmbmZmtqmUtCEnnA1OB0ZIWASeTrlpaB7hMEsC1EXFkRNwhaTZwJ6nr6aiIeKFVsZnVra8XAPjCAWunVl7FdFCh+Mxu5j8FOKVV8ZiZWe/4l9RmZlbkBGFmZkVOEGZmVuQEYWZmRU4QZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRW2/m6v1je/BY2bt5haEmZkVOUGYmVmRE4SZmRU1lSAk7SzpBklPSXpO0guSnmh1cGZmVp9mWxDfAg4C7gHWBT4EfLNVQZmZWf2avoopIuZLGpGf9PZ9Sde0MC4zM6tZswniaUlrA7dI+g9gCbBedwtIOgvYC1gaEdvnslHAhcAk4H7ggIh4TOn5o98A9gSeBg6LiJt6Xx2zoW11Lnf2pdLWW812MR0CjAA+BvwNmAC8p4dlzgZ2byg7AbgiIiYDV+RxgD2AyflvBnB6k3GZmVmLNNWCiIgH8uAzwOeaXOYqSZMaiqcBU/PwOcBc4Phcfm5EBHCtpI0kjY2IJc1sy8zM+l+3CULS7Ig4QNJtQDROj4gderm9zTo/9CNiiaRNc/k4YGFlvkW57CUJQtIMUiuDiRMn9nLzZmbWrJ5aEJ/I//dqcRwqlL0kIQFExCxgFkBHR0dxHjMzW33dJohKF88awJKI+DuApHWBzfqwvYc7u44kjQWW5vJFpPMancYDi/uwfjMz6yfNnqT+MfCPyvgLuay35gDT8/B04JJK+aFKdgYe9/kHM7N6NXuZ65oR8VznSEQ8ly977ZKk80knpEdLWgScDJwKzJZ0BLAA2D/P/ivSJa7zSZe5Ht6bSpiZWf9rNkEsk7RPRMwBkDQNeKS7BSLioC4m7VqYN4CjmozFzMzaoNkEcSRwnqRvkU4oLwQObVlUZmZWu2Z/B/EXYGdJ6wOKiCdbG5aZmdWtqQQhaR3SL6cnAWumO2NARHy+ZZGZmVmtmu1iugR4HLgReLZ14ZiZ2UDRbIIYHxGN91UyM7MhrNnfQVwj6dUtjcTMzAaUZlsQuwCHSbqP1MUk0tWpvb0Xk5mZDRLNJog9WhqFmZkNOE11MeXbfU8A3paHn252WTMzG5ya+pCXdDLpuQ0n5qK1gB+2KigzM6tfs62AdwP7kJ4mR0QsBjZoVVBmZla/ZhPEc/l+SQEgqdvnUZuZ2eDXbIKYLem/gY0kfRi4HDijdWGZmVndmr0X05clvR14AtgW+PeIuKylkZmZWa2avcyVnBCcFMzMholmb9b3JCufEb026Sqmv0XEhq0KzMzM6tVsF9MqVyxJ2hfYqa8blfQp4EOkpHMb6QlyY4ELgFHATcAh1afYmZlZe/Xpx24RcTHwtr4sK2kccDTQERHbAyOAA4HTgK9FxGTgMeCIvqzfzMz6R7NdTPtVRtcAOljZ5dTX7a4r6XlgJLCElHDen6efA8wETl+NbQw4M2fWHYGZWfOaPUm9d2V4BXA/MK0vG4yIByV9GVgAPANcSnrOxPKIWJFnWwSMKy0vaQYwA2DixIl9CcHMzJrQ7DmIw/trg5I2JiWXLYHlwI8p3wyw2EKJiFnALICOjo7VacWYmVk3mr0X0zmSNqqMbyzprD5uczfgvohYFhHPAz8F3kj6EV5nwhoPLO7j+s3MrB80e5J6h4hY3jkSEY8Br+vjNhcAO0saqfRw612BO4ErgffmeaaTHnNqZmY1afYcxBqSNs6JAUmjerHsKiLiOkkXkS5lXQHcTOoy+iVwgaQv5rIz+7J+Myvr60USvrhi+Gr2Q/4rpMeOXkQ6N3AAcEpfNxoRJwMnNxTfy2r8tsLMzPpXsyepz5U0j3QpqoD9IuLOlkZmZma16s0P5UaRbq/xTWCZpC1bFJOZmQ0Azf5Q7mTSj+O2Bb7PyifKval1oZnZQLA65yB8/mJw8xPlzMysyE+UMzOzIj9RzszMivxEOTMzK+oxQUgaAfw2InbDT5QzMxs2euxiiogXgKclvbwN8ZiZ2QDR7C+p/w7cJuky8pVMABFxdEuiMjOz2jWbIH6Z/8zMbJjoNkFImhgRCyLinHYFZGZmA0NP5yAu7hyQ9JMWx2JmZgNITwlCleGtWhmImZkNLD0liOhi2MzMhrieTlK/RtITpJbEunmYPB4RsWFLozMzs9p0myAiYkQrNpqfb/09YHtSy+SDwN3AhcAk4H7ggM4n2JmZWfv15nkQ/ekbwG8i4p+A1wB3AScAV0TEZOCKPG5mZjVpe4KQtCHwFvIzpyPiuYhYDkwDOi+nPQfYt92xmZnZSnW0ILYClgHfl3SzpO/l24dvFhFLAPL/TWuIzczMsjoSxJrAjsDpEfE60q07mu5OkjRD0jxJ85YtW9aqGM3Mhr06EsQiYFFEXJfHLyIljIcljQXI/5eWFo6IWRHREREdY8aMaUvAZmbDUdsTREQ8BCyUtG0u2hW4E5gDTM9l04FL2h2bmZmt1OzN+vrbx4HzJK0N3AscTkpWsyUdASwA9q8pNjMzo6YEERG3AB2FSbu2OxYzMyur63cQZmY2wDlBmJlZkROEmZkV1XWSelCbObPuCMzMWs8tCDMzK3KCMDOzIicIMzMrcoIwM7MiJwgzMytygjAzsyInCDMzK3KCMDOzIicIMzMrcoIwM7MiJwgzMytygjAzsyLfrM/MWqavN7b0DTEHhtpaEJJGSLpZ0i/y+JaSrpN0j6QL8+NIzcysJnV2MX0CuKsyfhrwtYiYDDwGHFFLVGZmBtSUICSNB94FfC+PC3gbcFGe5Rxg3zpiMzOzpK4WxNeB44B/5PFNgOURsSKPLwLGlRaUNEPSPEnzli1b1vpIzcyGqbafpJa0F7A0Im6UNLWzuDBrlJaPiFnALICOjo7iPGY2uK3OSWqf4O4/dVzF9CZgH0l7Ai8DNiS1KDaStGZuRYwHFtcQm5mZZW3vYoqIEyNifERMAg4E/iciDgauBN6bZ5sOXNLu2MzMbKWB9EO544FPS5pPOidxZs3xmJkNa7X+UC4i5gJz8/C9wE51xmNmZisNpBaEmZkNIE4QZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRU4QZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRU4QZmZWVOvtvs3M+ltfHznqR5W+lFsQZmZW1PYEIWmCpCsl3SXpDkmfyOWjJF0m6Z78f+N2x2ZmZivV0YJYARwTEa8CdgaOkjQFOAG4IiImA1fkcTMzq0nbz0FExBJgSR5+UtJdwDhgGjA1z3YO6VGkx7c7PjMbnlbnHMRQPX9R6zkISZOA1wHXAZvl5NGZRDbtYpkZkuZJmrds2bJ2hWpmNuzUliAkrQ/8BPhkRDzR7HIRMSsiOiKiY8yYMa0L0MxsmKslQUhai5QczouIn+bihyWNzdPHAkvriM3MzJI6rmIScCZwV0R8tTJpDjA9D08HLml3bGZmtlIdP5R7E3AIcJukW3LZZ4BTgdmSjgAWAPu3MoihelLJzKy/1HEV09WAupi8aztjMTOzrvmX1GZmVuQEYWZmRU4QZmZW5ARhZmZFThBmZlbk50GYma2mofoMCrcgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMhXMZmZ1WSgP8XOLQgzMytygjAzsyInCDMzK3KCMDOzIicIMzMrGnAJQtLuku6WNF/SCXXHY2Y2XA2oBCFpBPBtYA9gCnCQpCn1RmVmNjwNqAQB7ATMj4h7I+I54AJgWs0xmZkNSwPth3LjgIWV8UXAG6ozSJoBzMijT0m6u2Edo4FHWhbhwDKc6gqu71A2nOoK/VDfz31utba/RTMzDbQEoUJZrDISMQuY1eUKpHkR0dHfgQ1Ew6mu4PoOZcOprjB46jvQupgWARMq4+OBxTXFYmY2rA20BHEDMFnSlpLWBg4E5tQck5nZsDSgupgiYoWkjwG/BUYAZ0XEHb1cTZfdT0PQcKoruL5D2XCqKwyS+ioiep7LzMyGnYHWxWRmZgOEE4SZmRUNmQQxHG7RIel+SbdJukXSvFw2StJlku7J/zeuO86+knSWpKWSbq+UFeun5L/y8b5V0o71Rd57XdR1pqQH8/G9RdKelWkn5rreLemd9UTdd5ImSLpS0l2S7pD0iVw+5I5vN3UdfMc3Igb9H+mE9l+ArYC1gT8CU+qOqwX1vB8Y3VD2H8AJefgE4LS641yN+r0F2BG4vaf6AXsCvyb9dmZn4Lq64++Hus4Eji3MOyW/ptcBtsyv9RF116GX9R0L7JiHNwD+nOs15I5vN3UddMd3qLQghvMtOqYB5+Thc4B9a4xltUTEVcCjDcVd1W8acG4k1wIbSRrbnkhXXxd17co04IKIeDYi7gPmk17zg0ZELImIm/Lwk8BdpDsnDLnj201duzJgj+9QSRClW3R0d0AGqwAulXRjvuUIwGYRsQTSCxPYtLboWqOr+g3VY/6x3KVyVqW7cEjVVdIk4HXAdQzx49tQVxhkx3eoJIgeb9ExRLwpInYk3e32KElvqTugGg3FY346sDXwWmAJ8JVcPmTqKml94CfAJyPiie5mLZQNqjoX6jroju9QSRDD4hYdEbE4/18K/IzUDH24s+md/y+tL8KW6Kp+Q+6YR8TDEfFCRPwDOIOV3QxDoq6S1iJ9YJ4XET/NxUPy+JbqOhiP71BJEEP+Fh2S1pO0Qecw8A7gdlI9p+fZpgOX1BNhy3RVvznAoflql52Bxzu7Kgarhj72d5OOL6S6HihpHUlbApOB69sd3+qQJOBM4K6I+Gpl0pA7vl3VdVAe37rPkvfXH+mqhz+TrgA4qe54WlC/rUhXOvwRuKOzjsAmwBXAPfn/qLpjXY06nk9qej9P+lZ1RFf1IzXLv52P921AR93x90Ndf5DrcivpQ2NsZf6Tcl3vBvaoO/4+1HcXUrfJrcAt+W/PoXh8u6nroDu+vtWGmZkVDZUuJjMz62dOEGZmVuQEYWZmRU4QZmZW5ARhZmZFThBmTZD0VN0xmLWbE4RZC0kaUI/1NesNJwizPpK0t6TrJN0s6XJJm+XymZJmSboUOFfSSEmz803aLszLdOR5D1J6xsftkk6rtUJmDfztxqzvrgZ2joiQ9CHgOOCYPO2fgV0i4hlJxwKPRcQOkrYn/bIWSZsDp+V5HyPdqXffiLi47TUxK3CCMOu78cCF+R47awP3VabNiYhn8vAuwDcAIuJ2Sbfm8tcDcyNiGYCk80gPEnKCsAHBXUxmffdN4FsR8WrgI8DLKtP+Vhku3c65u3KzAcEJwqzvXg48mIendzPf1cABAJKmAK/O5dcBb5U0WtII4CDgdy2K1azX3MVk1pyRkhZVxr9KesbwjyU9CFxLep5wyXeAc3LX0s2ku3k+HhFLJJ0IXElqTfwqIoba7dptEPPdXM1aLLcO1oqIv0vamnRb620iPT/dbMByC8Ks9UYCV+anjAn4qJODDQZuQZiZWZFPUpuZWZEThJmZFTlBmJlZkROEmZkVOUGYmVnR/wHhKQNfknVvUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de  prueba\n",
      "------------------------\n",
      "Total de datos 3554\n",
      "Cantidad de datos positivos:  1751\n",
      "Cantidad de datos etiquetados negativamente:  1803\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: mostrar graficos en misma linea\n",
    "def stats_info(dataframe, label):\n",
    "    data_count = dataframe.count()[0]\n",
    "    positives_count = dataframe[dataframe.Sentiment == 1].count()[0]\n",
    "    negatives_count = dataframe[dataframe.Sentiment == 0].count()[0]\n",
    "\n",
    "    print(\"Dataset de \", label)\n",
    "    print(\"------------------------\")\n",
    "    print(\"Total de datos\", data_count)\n",
    "    print(\"Cantidad de datos positivos: \", positives_count)\n",
    "    print(\"Cantidad de datos etiquetados negativamente: \", negatives_count)\n",
    "\n",
    "    positive_text_lenghts = []\n",
    "    negative_text_lenghts = []\n",
    "\n",
    "    for i in range(data_count):\n",
    "        text = len(dataframe.Text[i])\n",
    "\n",
    "        if dataframe.Sentiment[i] == 0:\n",
    "            negative_text_lenghts.append(text)\n",
    "\n",
    "        else:\n",
    "            positive_text_lenghts.append(text)\n",
    "\n",
    "    plt.hist(positive_text_lenghts, alpha=0.5, bins = \"auto\", color='blue')\n",
    "    plt.title(\"Distribucion del largo de comentarios positivos\")\n",
    "    plt.xlabel('Largo')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(negative_text_lenghts, alpha=0.5, bins = \"auto\", color='red')\n",
    "    plt.title(\"Distribucion del largo de comentarios negativos\")\n",
    "    plt.xlabel('Largo')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.show()\n",
    "\n",
    "stats_info(df_train, \"entrenamiento\")\n",
    "stats_info(df_test, \"prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>R:</strong> Los histogramas mostrados corresponden a la distribucion del largo de palabras por cada clase. Se puede observar que en ambos tienden a una distribuciòn normal con sesgos hacia la izquierda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Construya un conjunto de validación desde el conjunto de entrenamiento para seleccionar modelos. Decida el tamaño dada la cantidad de ejemplos que se tienen para entrenamiento.\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train_text, df_val_text, labels_train, labels_val  = train_test_split(df_train_text, labels_train, test_size= choose size, random_state=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = range(df_train.shape[0])\n",
    "df_train_text, df_val_text, labels_train, labels_val  = train_test_split(df_train, labels_train, test_size= 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>could the whole plan here have been to produce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the stripped-down dramatic constructs , auster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.0</td>\n",
       "      <td>a nightmare date with a half-formed wit done a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1.0</td>\n",
       "      <td>you're not merely watching history , you're en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1.0</td>\n",
       "      <td>worth a look as a curiosity .\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                               Text\n",
       "179         0.0  could the whole plan here have been to produce...\n",
       "3416        1.0  the stripped-down dramatic constructs , auster...\n",
       "1627        0.0  a nightmare date with a half-formed wit done a...\n",
       "1101        1.0  you're not merely watching history , you're en...\n",
       "1118        1.0                    worth a look as a curiosity .\\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>could the whole plan here have been to produce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the stripped-down dramatic constructs , auster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.0</td>\n",
       "      <td>a nightmare date with a half-formed wit done a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1.0</td>\n",
       "      <td>you're not merely watching history , you're en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1.0</td>\n",
       "      <td>worth a look as a curiosity .\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                               Text\n",
       "179         0.0  could the whole plan here have been to produce...\n",
       "3416        1.0  the stripped-down dramatic constructs , auster...\n",
       "1627        0.0  a nightmare date with a half-formed wit done a...\n",
       "1101        1.0  you're not merely watching history , you're en...\n",
       "1118        1.0                    worth a look as a curiosity .\\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Realice un pre-procesamiento a los textos para normalizar un poco su estructura, para ello utilice el código de ejemplo a continuación, donde se pasa el texto a minúsculas (*lower-casing*), se reducen las mútliples letras, se eliminan palabras sin significados como artículos, pronombres y preposiciones (*stop word removal* [[3]](#refs)), además de pasar las palabras a su tronco léxico con la técnica de *lemmatizer* [[4]](#refs). Comente la importancia de un correcto pre-procesamiento en el domino de lenguaje natural.\n",
    "```python\n",
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "def base_word(word):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    return wordlemmatizer.lemmatize(word) \n",
    "def word_extractor(text):\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text) #substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ base_word(word.lower()) for word in word_tokenize(text) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords: #delete stopwords\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "... #try yourself\n",
    "word_extractor(\"I love to eat cake\")\n",
    "word_extractor(\"I love eating cake\")\n",
    "word_extractor(\"I loved eating the cake\")\n",
    "word_extractor(\"I do not love eating cake\")\n",
    "word_extractor(\"I don't love eating cake\")\n",
    "... #try yourself\n",
    "texts_train = [word_extractor(text) for text in df_train_text]\n",
    "texts_val = [word_extractor(text) for text in df_val_text]\n",
    "texts_test = [word_extractor(text) for text in df_test_text]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sebaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sebaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sebaa/nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sebaa/nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4591f5e7e2bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m...\u001b[0m \u001b[1;31m#try yourself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mword_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"I love to eat cake\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mword_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"I love eating cake\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mword_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"I loved eating the cake\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-4591f5e7e2bc>\u001b[0m in \u001b[0;36mword_extractor\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'([a-z])\\1+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'\\1\\1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#substitute multiple letter by two\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mwordtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mbase_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordtokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcommonwords\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#delete stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-4591f5e7e2bc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'([a-z])\\1+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'\\1\\1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#substitute multiple letter by two\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mwordtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mbase_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordtokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcommonwords\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#delete stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-4591f5e7e2bc>\u001b[0m in \u001b[0;36mbase_word\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbase_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mwordlemmatizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwordlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mword_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sebaa/nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sebaa\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def base_word(word):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    return wordlemmatizer.lemmatize(word) \n",
    "\n",
    "def word_extractor(text):\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text) #substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ base_word(word.lower()) for word in word_tokenize(text) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords: #delete stopwords\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "... #try yourself\n",
    "word_extractor(\"I love to eat cake\")\n",
    "word_extractor(\"I love eating cake\")\n",
    "word_extractor(\"I loved eating the cake\")\n",
    "word_extractor(\"I do not love eating cake\")\n",
    "word_extractor(\"I don't love eating cake\")\n",
    "... #try yourself\n",
    "texts_train = [word_extractor(text) for text in df_train_text]\n",
    "texts_val = [word_extractor(text) for text in df_val_text]\n",
    "texts_test = [word_extractor(text) for text in df_test_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d) Construya una representación vectorial a los textos de entrada para poder ser manejados y clasificados por los modelos de aprendizaje. Para ésto utilice el tipo de característica más común, que consiste en contar cuántas veces aparece cada términos/palabras en el texto, denominado **TF** (*term-frequency*). Para esto, se necesita contar con un vocabulario base, el cual se construirá a través de la unión de todas las palabras que observemos en los textos de entrenamiento ¿Cuáles son las palabras más frecuentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e8d4691c1485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#TF representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfeatures_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m...\u001b[0m \u001b[1;31m#transform val and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texts_train' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary=False) #TF representation\n",
    "vectorizer.fit(texts_train)\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "\n",
    "... #transform val and test\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e) Para tener una visión distinta y entender mejor la representación vectorial realizada, visualice los datos en un plano 2D. Para ésto utilice la técnica **LSA** (*Latent Semantic Analysis*) [[5]](#refs) que a diferencia de PCA, **no centra** los datos antes de realizar la descomposicipon SVD, de ésta manera podrá visualizar el espacio semántico de \"conceptos\" latentes usados en la representación. Coloree cada texto en base a su clase ¿Qué indica lo observado? Comente e interprete los resultados\n",
    "```python\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "model = TruncatedSVD(n_components=2)\n",
    "model.fit(features_train)\n",
    "x_plot = model.transform(features_train)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x_plot[:,0], x_plot[:,1], c=labels_train)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> f) Entrene un modelo de Regresión Logística Regularizado (utilizando como penalizador la norma $l_2$). Varíe el parámetro de regularización $C$, en potencias de 10, midiendo el error de predicción obtenido sobre los datos de entrenamiento y validación, construya un gráfico que muestre la variación de ambos errores respecto al parámetro $C$. Explique el significado y valor esperado del parámetro de regularización.\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xv,yv, param):\n",
    "    print(\"Param C= \",param)\n",
    "    model= LogisticRegression()\n",
    "    model.set_params(C=param)\n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "Cs = [10**i for i in np.arange(-4,4)]\n",
    "model, train_acc, test_acc = do_LOGIT(features_train,labels_train,features_val,labels_val, param= ...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> g) Entrene una Máquina de Soporte Vectorial (SVM) con distintos kernels. Similar a lo anterior, construya un gráfico que muestre la variación de ambos errores respecto al parámetro de regularización $C$ para cada tipo de kernel que experimente. Explique el significado y valor esperado de los parámetros en este modelo.\n",
    "```python\n",
    "from sklearn.svm import SVC as SVM #SVC is for classification\n",
    "def do_SVM(x,y,xv,yv, param, kernel='linear'):\n",
    "    print(\"Param C= \",C, 'Kernel= ', kernel)\n",
    "    model= SVM()\n",
    "    model.set_params(C=C,kernel=kernel) #try rbf and linear at least\n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "Cs = [10**i for i in np.arange(-4,4)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> h) Utilice el algoritmo de similaridad k-NN para intentar resolver el problema. Varíe el parámetro de los vecinos $k$ en un rango que estime conveniente y realice graficos de errores como en las preguntas anteriores. Comente sobre el valor esperado de este parámetro.\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def do_KNN(x,y,xv,yv, param):\n",
    "    model = KNeighborsClassifier()\n",
    "    print(\"Param K= \",param)\n",
    "    model.set_params(n_neighbors=param)\n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "Ks = np.arange(1, features_train.shape[1], steps)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> i) Entrene un Arbol de Decisión para resolver el problema. Varíe los parámetros de *max depth* y *min samples split* de manera separada, constuyendo gráficos de error respecto a estos parámetros. *Los valores que se presentan son sugerencias, no es necesario utilizar los mismos*. Comente sobre la diferencia entre la selección de estos dos parámetros.\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "def do_Tree(x,y,xv,yv, param_d=None, param_m=2):\n",
    "    model= Tree()\n",
    "    print(\"Param Max-D= \",param_d, 'Min-samples-S= ', param_m)\n",
    "    model.set_params(max_depth=param_d, min_samples_split=param_m) \n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "Depths = np.arange(1, features_train.shape[1], steps ) #choose steps\n",
    "SamplesS = np.arange(2, features_train.shape[0] , steps ) #choose steps\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> j) Utilice una Red Neuronal Artificial (ANN) para intentar resolver el problema, como la que se señala a continuación (utilizando el framework de *keras*): entrenada por 25 iteraciones al dataset (*epochs*) con un tamaño de *batch* de 128 para las actualizaciones de los pesos, utilizando *SGD* con una tasa de aprendizaje $0.1$ sobre la función de pérdida binaria de clasificación. La arquitectura de la red contiene una capa de salida con una única neurona que indica la probabilidad de que el texto sea positivo, una capa escondida con número de neuronas $N_h$ y la capa de entrada implícita para $x$. Varíe el parámetro que corresponde al número de neuronas en la capa oculta $N_h$, en potencias de 2, y vuelva a realizar el gráfico de error con respecto al parámetro. Comente.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "def do_ANN(x,y, xv,yv, param):\n",
    "    print(\"Neuron hidden = \",param)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=param, input_dim=x.shape[1], activation=\"sigmoid\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=SGD(lr=0.1), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x, y, epochs=25, batch_size=128, verbose=0)\n",
    "    train_acc = model.evaluate(x,y, verbose=0)[1] #in position 0 is the loss\n",
    "    test_acc = model.evaluate(xv,yv, verbose=0)[1]\n",
    "    return model, train_acc, test_acc\n",
    "N_h = [2**i for i in range(1,10)]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> k) Ahora evalúe sobre el conjunto de pruebas el mejor modelo obtenido, seleccionado en base a la métrica de desempeño en el conjunto de validación. Comente sobre la calidad obtenida en el problema trabajado ¿Es un buen valor? ¿Cuál podría ser un valor de referencia?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> l) Para comparar sus resultados utilice el modelo VADER (*Valence Aware Dictionary and sEntiment Reasoner*) [[6]](#refs), el cual entrega una *score* de predicción a nivel léxico (de palabras que comúnmente se asocian a una orientiación positiva o negativa). Este modelo construido manualmente no requiere entrenamiento, por lo que solo debe evaluar en conjunto de pruebas realizando predicciones del texto bruto (sin pre-procesamiento). Comente.\n",
    "```python\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "def vader_predict(sentences): \n",
    "    sid_obj = SentimentIntensityAnalyzer() \n",
    "    sent_v = []\n",
    "    for text in sentences:\n",
    "        sentiment_dict = sid_obj.polarity_scores(text) \n",
    "        if sentiment_dict[\"pos\"] > sentiment_dict[\"neg\"]: #based on scores\n",
    "            sent_v.append(1)\n",
    "        else:\n",
    "            sent_v.append(0)\n",
    "    return np.asarray(sent_v)\n",
    "vader_pred_test = vader_predict(df_test_text) \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels_test, vader_pred_test)\n",
    "```\n",
    ">> Para instalar VADER ejecute en consola:\n",
    "```\n",
    "pip install vaderSentiment\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> m) Bajo la idea del modelo VADER realice un análisis de qué palabras su modelo tiende a considerar como positivas o negativas por si solas. Algunos de los modelos estudiados en esta sección realizan una predicción probabilista, utilice uno de éstos para verificar lo solicitado. Sobre la representación *TF* genere datos de entradas que contengan una sola palabra del vocabulario para evaluar que predicción les genera su modelo a esas palabras. Muestre las palabras más negativas y positivas en el vocabulario consideradas por su modelo. Comente.\n",
    "```python\n",
    "V = len(vocab)\n",
    "word_scores = np.zeros((V, 2))\n",
    "for i in range(V):\n",
    "    x_word = np.zeros((1, V))\n",
    "    x_word[:,i] = 1 # only the \"i\" word appeared\n",
    "    word_scores[i] = model.predict_proba(x_word)\n",
    "vocab\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> n) Intente mejorar los resultados de otra manera. Varíe el pre-procesamiento realizado a los datos en c), por ejemplo eliminar símbolos, números o aplicar la técnica de *stemmming* [[7]](#refs) en lugar de *lemmatization* para llevar a su tronco léxico.\n",
    "```python\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "wordstemmer = PorterStemmer()\n",
    "wordstemmer.stem(word)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> o) Varíe la representación utilizada actualmente por alguna otra que ayude a mejorar el desempeño, por ejemplo reducir el peso de una palabra si es que aparece en muchos textos: TF-IDF. Existen varias opciones que podría realizar para mejorar el desempeño, por ejemplo reducir el vocabulario a las $K$ palabras más frecuentes, eliminar las palabras menos frecuentes, normalizar la representación, utilizar *n-gramas*, entre otras.\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer(binary=False, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, norm='l2', use_idf=True, sublinear_tf=False)\n",
    "tfidf_model.fit(texts_train)\n",
    "tfidf_model.transform(texts_train)\n",
    "... #for val and test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> p) Utilice métricas auxiliares para entender en qué falla su mejor modelo obtenido hasta el momento. ¿La información entregada indica cómo se podría mejorar o cual sería la causa de la falla?\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model, x, y):\n",
    "    print(\"Detailed Analysis Testing Results ...\")\n",
    "    print(classification_report(y, model.predict(x), target_names=['-','+']))\n",
    "score_the_model(model, features_test, labels_test )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> q) Algo que se puede modificar en algunos modelos de aprendizaje es poner peso en cada una de las clases, por ejemplo si una clase es de mayor interés que las otras e interesa reducir más su error. En *sklearn* ésto puede ser realizado con el parámetro de *class_weights*. Por ejemplo, asigne que detectar los textos negativos me interesa 5 veces más que detectar los textos positivos. Comente.\n",
    "```python\n",
    "classes_weights = {0: 5, 1: 1} #or choose..\n",
    "model.set_params(class_weight=classes_weights)\n",
    "model.fit(features_train, labels_train)\n",
    "score_the_model(model, features_test, labels_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> r) Visualice la clasificación que realiza su mejor modelo sobre algunos textos de pruebas ¿Qué entega mas información, una predicción categórica o una continua? ¿Cuál podría ser el beneficio de una o de otra? Comente\n",
    "```python\n",
    "test_pred = log_model.predict_proba(features_test) #or \".predict\"\n",
    "spl = np.random.randint( 0, len(test_pred), size=15)\n",
    "for text, pred_s, true_s in zip(df_test_text[spl], test_pred[spl], labels_test[spl]):\n",
    "    print(\"True sent: \", true_s, \"-- Pred sent: \",pred_s)\n",
    "    print(\"Raw text: \", text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> s) Comente sobre el desempeño obtenido por los diferentes modelos de aprendizaje utilizados al enfrentar el problema, ¿Dónde pareciera estar la mejora? ¿En la variación de los modelos y sus parámetros o en la modificación de la representación? ¿Cuál modelo de aprendizaje le parece mejor en base a su criterio? ya sea desempeño, tiempo de ejecución comodidad en las decisiones involucradas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Problema de Múltiples Anotaciones\n",
    "\n",
    "El aprendizaje supervisado visto en clases da cuenta que existe una única posible etiqueta $z$ (*ground truth*) asociada a un dato $x$ para poder aprender de los datos. Sin embargo, la definición del *ground truth* en algunos casos puede resultar bastante difícil de definir o bastante costoso, por ejemplo en problemas médicos donde se deben realizar invasivos exámenes para conocer la \"verdad absoluta\". Como alternativa se pueden recolectar múltiples anotaciones desde personas inexpertas en el área para poder estimar el *ground truth*. \n",
    "\n",
    "<img src=\"http://www.irishenvironment.com/wp-content/uploads/2013/11/crowdsourcing.jpg\" title=\"Title text\" width=\"40%\" />\n",
    "\n",
    "En esta actividad se trabajará en el caso en que contamos con múltiples anotaciones por cada dato de entrada $x_i$ dadas por personas inexpertas a través de Amazon Mechanical Turk (__[AMT](https://www.mturk.com/)__), es decir, $y^{(1)}, y^{(2)} \\ldots y^{(T_i)}$. El problema de predicción trabajado será el mismo de la actividad anterior, el análisis de sentimiento de un extracto de texto en Rotten Tomatoes. Los datos trabajados [[8]](#refs) pueden ser descargados de la página del autor.\n",
    "```\n",
    "wget http://fprodrigues.com//mturk-datasets.tar.gz\n",
    "```\n",
    "\n",
    "De esta manera trabajaremos con el archivo *mturk_answers.csv* en la carpeta *sentiment polarity* que se puede cargar con pandas. En este archivo se tendrán múltiples filas/registros por cada dato de entrenamiento, cada uno representando la etiqueta que entregó una persona (*worker*) a ese dato, los detalles de columnas son:\n",
    "* *WorkerId*: identificador de la persona que etiquetó/anotó el dato\n",
    "* *Input.id*: identificador del dato a etiquetar/anotar\n",
    "* *Input.original_sentence*: texto original del dato\n",
    "* *Input.stemmed_sent*: texto pre-procesado\n",
    "* *Input.true_sent*: sentimiento real (*ground truth*) del dato\n",
    "* *Answer.sent*:   etiqueta/anotación que entregó la persona\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./sentiment_polarity/mturk_answers.csv\") \n",
    "```\n",
    "\n",
    "> El objetivo de la actividad será el de obtener un modelo predictor del *ground truth* sin entrenar directamente con esto, sino que utilizar las múltiples anotaciones de las personas\n",
    "\n",
    "### Importante\n",
    "* Deberá crear un conjunto aleatorio de pruebas que solo contenga los textos y el sentimiento *ground truth* (sin repeticiones)\n",
    "* Los valores de *ground truth* están **solo para evaluar**, no puede utilizarlos para entrenar o tomar decisiones en su modelo.\n",
    "* La métrica de evaluación será el *accuracy score*\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "#### Sugerencias\n",
    "Para representar los textos, a diferencia de lo visto en la sección 1, se puede utilizar lo que son la representación vectorial de palabras (*word vectors*), a través de modelos especializados entrenados para aprender una representación en que palabras similares estén cercanas en el espacio vectorial. Puede utilizar los vectores livianos de __[GLOVE](https://nlp.stanford.edu/projects/glove/)__ en su versión entradas en textos de Wikipedia con 6 billones de palabras/tokens.\n",
    "```python\n",
    "EMBEDDING_DIM = 300\n",
    "GLOVE_FILE = \"./glove.6B.%dd.txt\"%(EMBEDDING_DIM)\n",
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE) as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "...\n",
    "embeddings_index.get(word)\n",
    "```\n",
    "> Para descargar GLOVE\n",
    "```\n",
    "wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] Keras: Deep Learning library for Theano and TensorFlow. https://keras.io/  \n",
    "[2] https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews  \n",
    "[3] https://en.wikipedia.org/wiki/Stopwords  \n",
    "[4] https://en.wikipedia.org/wiki/Lemmatisation  \n",
    "[5] Landauer, T. K., Foltz, P. W., & Laham, D. (1998). *An introduction to latent semantic analysis*. Discourse processes, 25(2-3), 259-284.  \n",
    "[6] https://github.com/cjhutto/vaderSentiment  \n",
    "[7] https://en.wikipedia.org/wiki/Stemming  \n",
    "[8] Rodrigues, F., Pereira, F., & Ribeiro, B. (2013). *Learning from multiple annotators: distinguishing good from random labelers*. Pattern Recognition Letters, 34(12), 1428-1436."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
